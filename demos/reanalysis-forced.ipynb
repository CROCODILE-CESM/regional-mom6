{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regional Tasmanian domain forced by GLORYS and ERA5 reanalysis datasets\n",
    "\n",
    "**Note**: FRE-NC tools are required to be set up, as outlined in the [documentation](https://regional-mom6.readthedocs.io/en/latest/) of regional-mom6 package.\n",
    "\n",
    "For this example we need:\n",
    "\n",
    "- [GEBCO bathymetry](https://www.gebco.net/data_and_products/gridded_bathymetry_data/)\n",
    "- [GLORYS ocean reanalysis data](https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/description), and\n",
    "- [ERA5 surface forcing](https://www.ecmwf.int/en/forecasts/dataset/ecmwf-reanalysis-v5)\n",
    "\n",
    "This example reads in the entire global extent of ERA5 and GEBCO; we don't need to worry about cutting it down to size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the `regional_mom6` package do?\n",
    "\n",
    "Setting up a regional model in MOM6 can be a pain. The goal of this package is that users should spend their debugging time fixing a model that's running and doing weird things, rather than puzzling over a model that won't even start.\n",
    "\n",
    "In running this notebook, you'll hopefully have a running MOM6 regional model. There will still be a lot of fiddling to do with the `MOM_input` file to make sure that the parameters are set up right for your domain, and you might want to manually edit some of the input files. *But*, this package should help you bypass most of the woes of regridding, encoding and understanding the arcane arts of the MOM6 boundary segment files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does this notebook do?\n",
    "This notebook is designed to set you up with a working MOM6 regional configuration. First, try to get it running with our default Tasmania case, then you can clone the notebook and modify for your region of interest. \n",
    "\n",
    "Input Type | Source | Subsets required\n",
    "---|---|---\n",
    "Surface | [ERA5 surface forcing](https://www.ecmwf.int/en/forecasts/dataset/ecmwf-reanalysis-v5) | Data from 2003; whole globe or subset around our domain\n",
    "Ocean | [GLORYS reanalysis product](https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/description) | Boundary segments & initial condition; see section 2 for details.   \n",
    "Bathymetry | [GEBCO](https://www.gebco.net/data_and_products/gridded_bathymetry_data/) | whole globe or subset around domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regional_mom6 as rmom6\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a dask client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Choose our domain, define workspace paths\n",
    "\n",
    "To make sure that things are working I'd recommend starting with the default example defined below. If this runs ok, then change to a domain of your choice and hopefully it runs ok too! If not, check the [README](https://github.com/COSIMA/regional-mom6/blob/main/README.md) and [documentation](https://regional-mom6.readthedocs.io/) for troubleshooting tips.\n",
    "\n",
    "You can log in and use [this GUI](https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/download) to find the lat/lon of your domain and copy paste below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = \"tasmania-example-reanalysis\"\n",
    "\n",
    "latitude_extent = [-48, -38.95]\n",
    "longitude_extent = [143, 150]\n",
    "\n",
    "date_range = [\"2003-01-01 00:00:00\", \"2003-01-05 00:00:00\"]\n",
    "\n",
    "## Place where all your input files go \n",
    "input_dir = Path(f\"mom6_input_directories/{expt_name}/\")\n",
    "\n",
    "## Directory where you'll run the experiment from\n",
    "run_dir = Path(f\"mom6_run_directories/{expt_name}/\")\n",
    "\n",
    "## Directory where compiled FRE tools are located (needed for construction of mask tables)\n",
    "toolpath_dir = Path(\"PATH_TO_FRE_TOOLS\")\n",
    "\n",
    "## Path to where your raw ocean forcing files are stored\n",
    "glorys_path = Path(\"PATH_TO_GLORYS_DATA\")\n",
    "\n",
    "## if directories don't exist, create them\n",
    "for path in (run_dir, glorys_path, input_dir):\n",
    "    os.makedirs(str(path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Make experiment object\n",
    "The `regional_mom6.experiment` contains the regional domain basics, and also generates the horizontal and vertical grids, `hgrid` and `vgrid` respectively, and sets up the directory structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt = rmom6.experiment(\n",
    "    longitude_extent = longitude_extent,\n",
    "    latitude_extent = latitude_extent,\n",
    "    date_range = date_range,\n",
    "    resolution = 0.05,\n",
    "    number_vertical_layers = 75,\n",
    "    layer_thickness_ratio = 10,\n",
    "    depth = 4500,\n",
    "    minimum_depth = 5,\n",
    "    mom_run_dir = run_dir,\n",
    "    mom_input_dir = input_dir,\n",
    "    toolpath_dir = toolpath_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now access the horizontal and vertical grid of the regional configuration via `expt.hgrid` and `expt.vgrid` respectively.\n",
    "\n",
    "Plotting the vertical grid with `marker = '.'` lets you see the spacing. You can use `numpy.diff` to compute the vertical spacings, e.g.,\n",
    "```python\n",
    "import numpy as np\n",
    "np.diff(expt.vgrid.zl).plot(marker = '.')\n",
    "```\n",
    "shows you the vertical spacing profile.\n",
    "\n",
    "### Modular workflow!\n",
    "\n",
    "After constructing your `expt` object, if you don't like the default `hgrid` and `vgrid` you can simply modify and then save them back into the `expt` object. However, you'll then also need to save them to disk again. For example:\n",
    "\n",
    "```python\n",
    "new_hgrid = xr.open_dataset(input_dir + \"/hgrid.nc\")\n",
    "```\n",
    "Modify `new_hgrid`, ensuring that _all metadata_ is retained to keep MOM6 happy. Then, save your changes\n",
    "\n",
    "```python\n",
    "expt.hgrid = new_hgrid\n",
    "\n",
    "expt.hgrid.to_netcdf(input_dir + \"/hgrid.nc\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Prepare ocean forcing data\n",
    "\n",
    "We need to cut out our ocean forcing. The package expects an initial condition and one time-dependent segment per non-land boundary. Naming convention is `\"east_unprocessed\"` for segments and `\"ic_unprocessed\"` for the initial condition.\n",
    "\n",
    "In this notebook, we are forcing with the Copernicus Marine \"Glorys\" reanalysis dataset. There's a function in the `mom6-regional` package that generates a bash script to download the correct boundary forcing files for your experiment. First, you will need to create an account with Copernicus, and you'll be prompted for your username and password when you try to run the bash script.\n",
    "\n",
    "The function is called `get_glorys_rectangular` because the fully automated setup is only supported for domains with boundaries parallel to lines of longitude and latitude. To download more complex domain shapes you can call `rmom6.get_glorys_data` directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt.get_glorys_rectangular(\n",
    "    raw_boundaries_path=glorys_path,\n",
    "    boundaries=[\"north\", \"south\", \"east\", \"west\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Set up bathymetry\n",
    "\n",
    "Similarly to ocean forcing, we point the experiment's `setup_bathymetry` method at the location of the file of choice and also provide the variable names. We don't need to preprocess the bathymetry since it is simply a two-dimensional field and is easier to deal with. Afterwards you can inspect `expt.bathymetry` to have a look at the regional domain.\n",
    "\n",
    "After running this cell, your input directory will contain other bathymetry-related things like the ocean mosaic and mask table too. The mask table defaults to a 10x10 layout and can be modified later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt.setup_bathymetry(\n",
    "    bathymetry_path='PATH_TO_GEBCO_FILE/GEBCO_2022.nc', \n",
    "    longitude_coordinate_name='lon',\n",
    "    latitude_coordinate_name='lat',\n",
    "    vertical_coordinate_name='elevation',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out your domain!\n",
    "\n",
    "Calling `expt.bathymetry` returns an xarray dataset, which can be plotted as usual. If you haven't yet run setup_bathymetry, calling `expt.bathymetry` will return `None` and prompt you to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output",
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "expt.bathymetry.depth.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 5: Handle the ocean forcing - where the magic happens\n",
    "\n",
    "This cuts out and interpolates the initial condition as well as all boundaries (unless you don't pass it boundaries).\n",
    "\n",
    "The dictionary maps the MOM6 variable names to what they're called in your ocean input file. Notice how for GLORYS, the horizontal dimensions are `latitude` and `longitude`, vs `xh`, `yh`, `xq`, `yq` for MOM6. This is because for an 'A' grid type tracers share the grid with velocities so there's no difference.\n",
    "\n",
    "If one of your segments is land, you can delete its string from the 'boundaries' list. You'll need to update MOM_input to reflect this though so it knows how many segments to look for, and their orientations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from the GLORYS variables and dimensions to the MOM6 ones\n",
    "ocean_varnames = {\"time\": \"time\",\n",
    "                  \"yh\": \"latitude\",\n",
    "                  \"xh\": \"longitude\",\n",
    "                  \"zl\": \"depth\",\n",
    "                  \"eta\": \"zos\",\n",
    "                  \"u\": \"uo\",\n",
    "                  \"v\": \"vo\",\n",
    "                  \"tracers\": {\"salt\": \"so\", \"temp\": \"thetao\"}\n",
    "                  }\n",
    "\n",
    "# Set up the initial condition\n",
    "expt.setup_initial_condition(\n",
    "    glorys_path / \"ic_unprocessed.nc\", # directory where the unprocessed initial condition is stored, as defined earlier\n",
    "    ocean_varnames,\n",
    "    arakawa_grid=\"A\"\n",
    "    )    \n",
    "\n",
    "# Set up the four boundary conditions. Remember that in the glorys_path, we have four boundary files names north_unprocessed.nc etc. \n",
    "expt.setup_ocean_state_boundaries(\n",
    "        glorys_path,\n",
    "        ocean_varnames,\n",
    "        boundaries = [\"south\", \"north\", \"west\", \"east\"],\n",
    "        arakawa_grid = \"A\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out your initial condition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depends on Matplotlib\n",
    "# expt.init_tracers.salt.isel(zl = 0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can plot your segment data too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depends on Matplotlib\n",
    "#expt.segment_001.u_segment_001.isel(time = 5).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run the FRE tools\n",
    "\n",
    "This is just a wrapper for the FRE tools needed to make the mosaics and masks for the experiment. The only thing you need to tell it is the processor layout. In this case we're saying that we want a 10 by 10 grid of 100 processors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt.run_FRE_tools(layout=(10, 10)) ## Here the tuple defines the processor layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Set up ERA5 forcing:\n",
    "\n",
    "Here we assume the ERA5 dataset is stored somewhere on the system we are working on. \n",
    "\n",
    "Below is a table showing ERA5 characteristics and what needs to be done to sort it out.\n",
    "\n",
    "**Required ERA5 data**:\n",
    "\n",
    "Name | ERA5 filename | ERA5 variable name | Units\n",
    "---|---|---|---\n",
    "Surface Pressure | sp | sp | Pa \n",
    "Surface Temperature | 2t | t2m | K \n",
    "Meridional Wind | 10v | v10 | m/s \n",
    "Zonal Wind | 10u | u10 | m/s \n",
    "Specific Humidity | - | - | kg/kg, calculated from dewpoint temperature\n",
    "Dewpoint Temperature | 2d | d2m | K\n",
    "\n",
    "\n",
    "We calculate specific humidity $q$ from dewpoint temperature $T_d$ and surface pressure $P$ via saturation vapour pressure $P_v$.\n",
    "\n",
    "$$P_v = 10^{8.07131 - \\frac{1730.63}{233.426 + T}} \\frac{101325}{760} \\; \\textrm{[Pascal]} $$\n",
    "\n",
    "$$q = 0.001 \\times 0.622  \\frac{P_v}{P}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "expt.setup_era5(\"PATH_TO_ERA5_DATA/era5/single-levels/reanalysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Modify the default input directory to make a (hopefully) runnable configuration out of the box\n",
    "\n",
    "This step copies the default directory and modifies the `MOM_layout` files to match your experiment by inserting the right number of x, y points and CPU layout.\n",
    "\n",
    "To run MOM6 using the [payu infrastructure](https://github.com/payu-org/payu), provide the keyword argument `using_payu = True` to the `setup_run_directory` method and an example `config.yaml` file will be appear in the run directory. The `config.yaml` file needs to be modified manually to add the locations of executables, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt.setup_run_directory(surface_forcing = \"era5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Run and Troubleshoot!\n",
    "\n",
    "To run the regional configuration first navigate to your run directory in terminal and use your favourite tool to run the experiment on your system. \n",
    "\n",
    "Ideally, MOM6 runs. If not, the first thing you should try is reducing the timestep. You can do this by adding `#override DT=XXXX` to your `MOM_override` file. \n",
    "\n",
    "If there's strange behaviour on your boundaries, you could play around with the `nudging timescale` (an example is already included in the `MOM_override` file). Sometimes, if your boundary has a lot going on (like all of the eddies spinning off the western boundary currents or off the Antarctic Circumpolar current), it can be hard to avoid these edge effects. This is because the chaotic, submesoscale structures developed within the regional domain won't match the flow at the boundary. \n",
    "\n",
    "Another thing that can go wrong is little bays that create non-advective cells at your boundaries. Keep an eye out for tiny bays where one side is taken up by a boundary segment. You can either fill them in manually, or move your boundary slightly to avoid them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vroom_clean_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
